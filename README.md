# Oral-Cancer-Detection

Oral cancer is cancer that develops in the tissues of the mouth or throat. It belongs to a larger group of cancers called head and neck cancers. Most develop in the squamous cells found in your mouth, tongue, and lips.

Oral cancer is a major health problem worldwide accounting for 177,384 deaths in 2018 and is most prevalent in low- and middle-income countries. Enabling automation in the identification of oral cancer can lead to the prevention and early diagnostic of disease. Therefore, regular oral check-ups are very important. The focus of transfer learning is to enhance the performance of target learners on target domains by inheriting knowledge from various conceptually related source domain. This project implies a novel approach for the early diagnosis and detection of one of the leading diseases, cancer in most sensory body organ i.e., mouth. In addition to this, deep neural networks are used to build automated systems, where complex patterns are derived to track with this difficult task. Various Transfer Learning architectures has been improvised and comparative analysis has been derived to focus the best learning rate. Further analysis is reported in relation to the classification of the referral decision. Our introductory results shows that deep learning has the power to tackle this challenging task. 

In the enlargement of cells that provide with harmed nearby tissues, oral cancer has been documented to be intractable [1]. Oral cancer can be detected in the early stages of mouth cancer, known as ulcers, by a tiny number of sterile cells in the oral tissue. When it comes to metabolism, dead cells can be found in remote places of the geographical region or inside the body. There are several types of cancer, however 90 percent of crab cells are classified as oral cancer [2]. Biological models, as well as clinical forms of related and lesion-free tumour models, can be detected in various parts of the body using appearance models and stereotypes that do not require staining. Machine learning techniques were utilised to predict several biological models for oral cancer, which were used to classify non-cancerous and cancerous samples, which were then analysed for the oral cancer stage [3]. The predictor will use three justification test kits as well as different stages of cancer to determine the accuracy of the interaction. Sampling with sample justification can predict different tumour volumes and the emergence of ulcers in the tissues, assisting in the prediction of different stages of oral cancer 
[4]. 

Without the need of any special instruments, the oral cavity can be easily viewed. During clinical practise, specialists use visual inspection to make suspected diagnoses of oral cancer based on their own knowledge and experience with the visual appearances of malignant tumours [5,6]. Oral cancer lesions typically appear as white patches followed by red patches, or as mixed white-red patches in rare cases. The mucosal surface frequently becomes progressively uneven, grainy, and ulcerated [7,8]. Non-specialist medical workers, however, sometimes misinterpret these visual patterns as indicators of ulceration or other types of oral mucous membrane illnesses [8]. For the detection of oral cancer, there is no established vision based technique. Oral cancer is diagnosed through oral biopsy, which takes a long time and is not always available in primary care or community settings, especially in developing countries [9, 10]. As a result, Oral Cancer patiens are frequently unable to acquire prompt diagnosis and referrals [11,12]. 

There is a lot of evidence that Deep learning algorithms can match, and in some cases outperform, human experts when it comes to identifying minute or miniscule visual patterns 
from photographs,[13], classifying skin lesions, [14], detecting diabetic retinopathy, [15], and identifying facial phenotypes of genetic disorders [16]. These findings lead us to anticipate that deep learning could capture fine-grained aspects of oral cancer lesions, which would be useful in the early diagnosis of the disease. 

The concept of transfer learning is founded on the premise that when knowledge or information from a related domain is transferred to it, it improves an idea in that domain. Consider the case of two people who want to learn to play the flute. One of the participants has no prior musical experience, while the other has a strong understanding of music as a result of playing the sitar. By applying previously learned music knowledge to the process of learning to play the flute, a person with a good music background will be able to learn the flute more quickly [17]. 


A deep learning system was built using photographic images for entirely automated oral cancer detection when it was assumed that deep neural networks could quickly identify 
certain visual patterns of oral cancer just like any human expert. On both internal and external validation datasets, we calculated algorithmic performance and compared the model to the average result of seven oral cancer specialists on a clinical validation dataset. Our findings demonstrated that oral cancer lesions have discriminative visual patterns that can be discovered using a deep learning algorithm. The potential to identify oral cancer at the point of care in a less expensive, non-invasive, and effective method has substantial clinical implications. 

**Dataset**

Extract the dataset and model from [https://drive.google.com/drive/folders/1uL3LTG60HsMNkctTbbkNi9aulXmUMP5z?usp=sharing](url)

**Technology Used:**

Deep Learning

Transfer Learning

Python [programming language]

**Reference**

[1] Oral cancer, https://en.wikipedia.org/wiki/Oral_cancer 

[2] Oral Leukplakia LM328 “https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM65276” 

[3] Oral cancer, https://www.webmd.com/oral-health/guide /oral-cancer#1

[4] Head-and-Neck-squamous-cellcarcinoma, https://en.wikipedia.org/wiki/Head_and_neck_squamous_cell_carcinom, Wikipedia(2018).

[5] der Waal I, de Bree R, Brakenhoff R, Coebegh JW. Early diagnosis in primary oral cancer: is it possible? Med Oral Patol Oral Cir Bucal 2011;16:e300–5. 

[6] Kundel HL. History of research in medical image perception. J Am Coll Radiol 2006;3:402–8. 

[7] Chi AC, Day TA, Neville BW. Oral cavity and oropharyngeal squamous cell carcinoma—An update. CA Cancer J Clin 2015;65:401–21. 

[8] Bagan J, Sarrion G, Jimenez Y. Oral cancer: clinical features. Oral Oncol 2010;46:414–7. 

[9] Moy E, Garcia MC, Bastian B, Rossen LM, Ingram DD, Faul M, et al. Leading causes of death in nonmetropolitan and metropolitan areas - United States, 1999-2014. MMWR Surveill Summ 2017;66:1–8. 

[10] Pagedar NA, Kahl AR, Tasche KK, Seaman AT, Christensen AJ, Howren MB, et al. Incidence trends for upper aerodigestive tract cancers in rural United States counties. Head Neck 2019;41:2619–24.

[11] Gigliotti J, Madathil S, Makhoul N. Delays in oral cavity cancer. Int J Oral Maxillofac Surg 2019;48:1131–7. 

[12] Liao DZ, Schlecht NF, Rosenblatt G, Kinkhabwala CM, Leonard JA, Ference RS, et al. Association of delayed time to treatment initiation with overall survival and recurrence among patients with head and neck squamous cell carcinoma in an underserved urban population. JAMA Otolaryngol - Head Neck Surg 2019;145:1001–9. 

[13] LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521:436–44. 

[14] Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, et al. Dermatologist level classification of skin cancer with deep neural networks. Nature 2017;542:115–8.

[15] Gulshan V, Peng L, Coram M, Stumpe MC, Wu D, Narayanaswamy A, et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA J Am Med Assoc 2016;316:2402– 10. 

[16] Gurovich Y, Hanani Y, Bar O, Nadav G, Fleischer N, Gelbman D, et al. Identifying facial phenotypes of genetic disorders using deep learning. Nat Med 2019;25:60– 4. 

[17] Pan SJ, Yang Q. A survey on transfer learning. IEEE Trans Knowl Data Eng. 2010;22(10):1345–59.
